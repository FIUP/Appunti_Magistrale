% !TEX encoding = UTF-8
% !TEX program = pdflatex
% !TEX root = InformationRetrieval.tex
% !TEX spellcheck = it-IT

% 27 Ottobre 2016
% \subsection{Pesatura dei termini}

Un altro modo per calcolare i pesi dei termini è l'\textbf{inverse document frequency} (\textbf{idf}) che riflette l'importanza di un termine nella collezione dei documenti.

L'idea alla base è che se un termine è presente in tanti documenti, questo sarà meno utile per discriminare i vari documenti e quindi è poco importante anche per il reperimento.

La tipica forma dell'\textit{idf} è

$$
idf_k = \log\bigg(\frac{N}{n_k}\bigg)
$$

\noindent dove $k$ è l'indice del termine, $N$ è la dimensione della collezione e $n_k$ è il numero delle occorrenze di $k$ all'interno della collezione.

Questo modello di calcolo è stato sviluppato in modo intuitivo e sperimentale, ma è stato poi ri-ottenuto utilizzando il modello probabilistico.

Quindi per calcolare il peso del termine $k$ nel documento $i$ si usa la formula:

$$
d_{i,k} = \underbrace{\log (f_{i,k} +1 )}_{tf_k} \cdot \underbrace{\log\bigg(\frac{N}{n_k}\bigg)}_{idf_k}
$$

\noindent E in modo analogo può essere calcolata per la query, con la differenza che il più delle volte viene considerato solamente $idf_k$ perché tipicamente nella query ogni termine compare una volta sola.

$$
q_k = \log(f_k +1 )\cdot \log \bigg(\frac{N}{n_k}\bigg)
$$

\noindent Ovviamente i pesi devono essere calcolati solamente per i termini che sono presenti nella query.

\section{Modello probabilistico}

Il modello probabilistico è alla base dei migliori modelli di reperimento dell'informazione.

La ricerca riguardo questi modelli inizia negli anni '70, quando la possibilità di effettuare calcoli complessi è molto limitata.

\subsection{Basi di probabilità}

Partiamo da un esperimento che può avere degli esiti $\omega_1, \omega_2, \omega_3, \ldots$ e l'insieme di questi esiti prende il nome di spazio campionario $\Omega$.

Gli esiti possono essere poi raggruppati in \textbf{eventi semplici} se ci si riferisce solamente ad un esito, oppure di \textbf{eventi composti} quando ci si riferisce ad un sotto-insieme degli esiti. 

La probabilità è quindi una funzione che dato un esito gli associa un numero, secondo 3 assiomi:

\begin{enumerate}
	\item $P(\text{Evento}) \geq 0$
	\item $P(E_i \cup E_j) = P(E_i) + P(E_j) $ se $E_i \cap E_j = \emptyset$
	\item $P(\Omega) = 1$
\end{enumerate}

Una \textbf{variabile aleatoria} X è una funzione $X(\omega) : \Omega \rightarrow \mathbb{R}$ che associa un numero ad un esito.

Ad esempio, supponendo di avere come esperimento il lancio di due monete. Gli esiti di questo esperimento sono delle coppie del tipo $\omega_1 = (T,T)$, ecc. Su questo esperimento si può definire la variabile aleatoria $X = $``quante teste ho'', ovvero $X(\omega_1) = 2, X(\omega_2) = X(\omega_3) = 1$ e $X(\omega_4) = 0$.

A partire da questo ci si può chiedere ``\textit{qual'è la probabilità che $X = 2$?}''. Per fare questo sappiamo che $P(X = 2) = P(\omega_1) = 0.25$, perché questo evento si può verificare solo con un particolare esito sui 4 possibili.
In modo simile $P(X = 1) = P(\omega_2 \cup \omega_3) = P(\omega_2) + P(\omega_3) = 0.5$.

Consideriamo ora le due variabili aleatorie $X =$``testa o croce per la moneta 1'' e $Y =$``testa o croce per la moneta 2'', la probabilità congiunta $P(X,Y)$ è la probabilità relativa alle due variabili aleatorie per lo stesso esperimento. \`E importante discriminare se si tratta dello esperimento o meno, perché le due variabili possono influenzarsi tra loro.

Se le due variabili sono tra loro indipendenti si ha che

$$
P(X,Y) = P(X)P(Y)
$$

\noindent A partire dalla probabilità congiunta si può definire la probabilità condizionata, ovvero la probabilità che si verifichi l'evento $X$, sapendo che si è verificato $Y$:

$$
P(X | Y) = \frac{P(X,Y)}{P(Y)}
$$

\noindent Esiste poi anche il concetto di indipendenza condizionata

$$
P(X,Y | Z) = P(X|Z) P(Y|Z)
$$

\noindent Con questi concetti è possibile definire la \textbf{regola della somma}

$$
P(X) = \sum\limits_{y} P(X,Y)
$$

\noindent e la \textbf{regola del prodotto}:

$$
P(X,Y) = P(X|Y)P(Y)
$$

\noindent C'è poi la \textbf{regola di Bayes}:

$$
P(X,Y) = P(X|Y)P(Y) = P(Y|X)P(X)
$$

\noindent da qui posso andare ad effettuare predizione, perché supponendo di avere gli esiti delle singole variabili aleatorie, riesco a calcolare

$$
P(X|Y) = \frac{P(Y|X)P(X)}{P(Y)}
$$

\noindent Supponiamo di voler fare predizione per classificare correttamente una mail come spam o meno. Prendiamo quindi in considerazione le variabili aleatorie $C = $ ``class'' che può assumere due valori $s$ o $h$ e $W$ che vale $l$ se la mail contiene la parola ``lottery'' e $\overline{l}$ se questa non compare.
Supponiamo inoltre che $P(C = h) = 0.7$ e $P(C = s) = 0.3$. Con queste informazioni ci conviene mettere tutto nella cartella non-spam, perché in questo caso entrambi gli errori di classificazione hanno lo stesso costo. Tipicamente però classificare una mail buona come spam ha un costo di gran lunga maggiore e quindi non sempre preferire la classe con probabilità maggiore è la scelta giusta.
Però possiamo sfruttare l'informazione riguardo la parola lotteria. Se però consideriamo anche il contenuto della mail, possiamo osservare se nella mail compare la parola ``lottery'' e quindi considerare $P(C = s | W = l)$. Questo valore però non è noto, ma si può utilizzare Bayes per calcolarlo:

$$
P(C = s | W = l) = \frac{P(W = l | C = s)P(C=s)}{P(W = l)}
$$

\noindent Il vantaggio di questa nuova formulazione è che possiamo calcolarci sia $P(W = l | C = s)$ che $P(w = l)$ andando a controllare le mail presenti nella cartella spam.
Andando a controllare abbiamo osservato che $P(W = l | C = s) = 3/5$ e quindi possiamo calcolarci la probabilità di interesse.

Tuttavia bisogna tenere conto che possono capitare dei casi limite in cui la parola ``lottery'' non viene mai trovata nelle mail già classificate come spam, oppure è presente su tutte. Per gestire questi casi è quindi necessario utilizzare dei fattori di correzione.

Per calcolare $P(W = l)$ possiamo utilizzare la probabilità congiunta:

\begin{align*}
	P(W = l)&= \sum\limits_{C} P(W = l, C) \\
			&= \sum\limits_{C} P(W = l | C)P(C)
\end{align*}

\noindent che può essere calcolata con i dati a disposizione (sappiamo che $P(W = l | C = h) = 6/8$).

Andando quindi a sostituire tutto abbiamo:

\begin{align*}
	P(C = s | W = l) &\approxeq 0.51
\end{align*}

\noindent La cosa interessante è che man mano che i dati aumentano riesco ad avere delle stime migliori delle priorità.

Tipicamente si cerca di ricondursi al caso in cui la variabile aleatoria segue un comportamento Bernulliano:

$$
P(X) = \begin{cases}
p \quad& x= 1 \\
1-p \quad& x=0
\end{cases} \rightarrow P(X = x) p^x(1-p)^{1-x}
$$

\noindent Supponiamo che questo esperimento venga ripetuto più volte e di voler calcolare la probabilità che si verifichi una certa combinazione di esiti:

$$
P(X = x^1, X=x^2, ... X = x^n | C = h)
$$

\noindent Effettuare il calcolo della probabilità di questa distribuzione può essere molto pesante se il numero di esperimenti è elevato.
Vengono quindi fatte delle ipotesi che permettono di semplificare il calcolo:

\begin{enumerate}
	\item L'esito di un esperimento non influenza gli altri.
	\item Le probabilità di un determinato esito rimangono costanti, ovvero le varie variabili aleatorie sono identiche.
\end{enumerate}

\noindent le variabili che seguono queste ipotesi prendono il nome di \textbf{i.i.d.}.
Ad esempio, nel caso delle mail si assume che la probabilità di della parola ``lottery'' in una mail non influenzi la probabilità della presenza nelle altre mail e che la probabilità che questa sia presente non vari nel tempo.

Sotto queste ipotesi, possiamo effettuare il calcolo con

$$
P(X = x^1, X=x^2, ... X = x^n | C = h) = \underbrace{\prod\limits_{j = 1}^{n} P(X_j | C)}_{\text{per l'indipendenza}} = \underbrace{\prod\limits_{i = 1}^{n} p^{x^j}(1-p)^{1-{x^j}}}_{\text{per la probabilità uguale}}
$$

\noindent Per trovare il valore di $p$ che più si avvicina alla sequenza di osservazioni è necessario effettuare la derivata della formula precedente e porla uguale a 0. Questo calcolo è complesso e quindi si preferisce effettuare la derivata del logaritmo.

