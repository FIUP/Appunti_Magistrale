\section{Lezione 2 - Ripasso di
probabilità}\label{lezione-2---ripasso-di-probabilituxe0}

(Kaggle){[}https://www.kaggle.com/{]}, sito che offre sfide con problemi
di machine learing sponsorizzati da grandi compagnie.

\textbf{Proposta di un progetto di gruppo (opzionale):} affrontare uno
dei problemi proposti da Kraggle per ottenere un bonus sul voto finale.

\subsection{Problemi tipici in modo
matematico}\label{problemi-tipici-in-modo-matematico}

\emph{Notazione: * Ø --\textgreater{} teta, insieme di parametri che
rappresenta l'apprendimento (lo so è il simbolo dell'insieme vuoto, ma è
semplice da fare) * X --\textgreater{} insieme di dati su cui applicare
l'algoritmo * Y --\textgreater{} enumeratore (etichette)}

\begin{itemize}
\tightlist
\item
  Classificazione binaria: h(Ø):
  \texttt{X\ -\/-\textgreater{}\ \{-1,+1\}} (\emph{h di teta}, funzione
  che mappa un dato valore in -1 o +1 (oppure 0 o 1) la funzione
  \emph{h} è sempre parametrica, in qunato i parametri rappresentano
  l'apprendimento (\emph{teta} Ø));
\item
  Classificazione multiclasse: \texttt{h(Ø):\ X\ -\/-\textgreater{}\ Y}
  con Y che prende come valori un enumeratore o un intervallo di numeri
  1..k;
\item
  Regressione: \texttt{h(Ø):\ X\ -\/-\textgreater{}\ Reale}
\item
  Ranking di istanze e classi:
  \texttt{h(Ø):\ XxY\ -\/-\textgreater{}\ Reale} dati elementi del
  prodotto cartesiano tra X (esempio) e Y (etichetta) associa un
  punteggio espresso da un numero reale. Una funzione che valuta la
  coppia (x,y) con \emph{x} valore e \emph{y} classificazione.
\item
  Novelty detection: \texttt{h(Ø):\ X\ -\/-\textgreater{}\ {[}0,1{]}}
  funzione che dato un'esempio mi calcola il fattore di rischio come
  numero reale da 0 a 1.
\item
  Clustering: \texttt{h(Ø):\ X\ -\/-\textgreater{}\ \{1,..,k\}} funzione
  che ad un esempio associa una valutazione.
\item
  Associazioni (Basket Analysis): \texttt{P(Y\textbar{}X)}.
\end{itemize}

\subsection{Ripasso di probabilità e
statistica}\label{ripasso-di-probabilituxe0-e-statistica}

\emph{Evento}: qualcosa che può essere o vero o falso.

La probabilità che si verifichi un'evento è un numero compreso tra 0 e
1, \texttt{0\ \textless{}=\ P(E)\ \textless{}=\ 1}. Questo numero può
essere calcolato usando la frequenza con la quale si verifica l'evento.

Dato un insieme di eventi E\_i mutuamente esclusivi tra loro. La
probabilità dell'unione di tutti gli eventi è la somma delle probabilità
dei singoli eventi.

La probabilità che si verifichi un evento o il suo complementare è 1.
(sempre se gli eventi sono mutuamente esclusivi).

La probabilità dell'unione di due eventi non esclusivi è data dalla
probabilità che si verifichi uno o l'altro, meno la probabilità che si
verifichino entrambi contemporaneamente.

\texttt{P(E\ unito\ F)\ =\ P(E)+P(F)+P(E\ intersecato\ F)}

\textbf{Probabilità condizionale}: probabilità che l'evento E accada
sapendo che si è verificato l'evento F \texttt{P(E\textbar{}F)}.

L'evento E è indipendente da F se \texttt{P(E\textbar{}F)\ =\ P(E)}.

\texttt{P(E\ intersecato\ F)\ =\ P(E\textbar{}F)*P(F)\ =\ P(F\textbar{}E)*P(E)}

\textbf{Formula di Bayes}

\texttt{P(F\textbar{}E)\ =\ {[}P(E\textbar{}F)P(F){]}\ /\ P(E)}

Deriva dalla probabilità condizionata, sarà utile nella classificazioni
di tipo \emph{bayesiano} (non sono sicuro che sia scritto giusto).

Dato un insieme di eventi F\_i, tra loro esclusivi ed esasutivi (gli Fi
coprono tutti i possibili esiti, la propabilità dell'unione di tutti gli
F\_i è 1). Allora \texttt{E\ =\ unione\ su\ i\ (E\ intersecato\ F\_i)},
la probabilità di E è quindi uguale alla sommatoria della probabilità di
tutte le intersezioni.

Il tutto per arrivare a:

\texttt{P(F\_i\ \textbar{}\ E)\ =\ {[}P(E\ \textbar{}\ F\_i)P(F\_i){]}\ /\ sommatoria\ su\ j\ (\ P(E\textbar{}F\_j)P(F\_j))}

\textbf{Valore atteso}: detto anche media, con X e Y variabili
aleatorie.

\texttt{E{[}X{]}\ =\ sommatoria\ su\ i\ (x\_i\ *\ P(x\_i))}

\texttt{E{[}aX\ +\ b{]}\ =\ aE{[}X{]}\ +\ b}

\texttt{E{[}X\ +\ Y{]}\ =\ E{[}X{]}\ +\ E{[}Y{]}}

\texttt{E{[}g(X){]}\ =\ sommatoria\ su\ i\ (g(x\_i)\ *\ P(x\_i))}

\texttt{E{[}X\^{}n{]}\ =\ sommatoria\ su\ i\ ((x\_i)\^{}n\ *\ P(x\_i))}
detto anche n-esimo momento

\textbf{Varianza}: quanto varia il valore ottenuto attorno alla media
dei vari esperimenti.

\texttt{sigma\^{}2\ =\ VAR(X)\ =\ E{[}\ (X-mu)\^{}2\ {]}} dove
\texttt{mu} è il valore atteso. \texttt{=\ E{[}X\^{}2{]}\ -\ mu\^{}2}.

\textbf{Deviazione standard}: o scarto quadratico medio, è la radice
quadrata della varianza, ed è la media di quando ci si discosta dal
valore attesso.
